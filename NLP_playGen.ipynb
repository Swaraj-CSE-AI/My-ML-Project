{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNn6rM2VrCov/SYcdzyoCIi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swaraj-CSE-AI/My-ML-Project/blob/main/NLP_playGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MNxnnrjYc30j"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "tKgyxFeXfCzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "id": "LJEORKmEdnDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f98fed-adb4-4ad9-e023-ee38b64664b9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load own file"
      ],
      "metadata": {
        "id": "rJV-fZ0IeNfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# path_to_file = list(files.upload().keys())[0]"
      ],
      "metadata": {
        "id": "fREGxJuEdYNv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text  = open (path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print('Length of text: {} charecters'.format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxYtD28Pd2-s",
        "outputId": "309a0591-2d9b-46b3-83fa-969be8826dbe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 charecters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3HQ1GVneqmy",
        "outputId": "cc1476aa-9699-4a5e-9ad1-700a824d219d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding"
      ],
      "metadata": {
        "id": "d0WUFZfklek5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "text_as_int = text_to_int(text)"
      ],
      "metadata": {
        "id": "fsaUhK4-evbo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"text:\", text[:13])\n",
        "print(\"Encoded:\", text_to_int(text[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxFJsf7-lIiL",
        "outputId": "583439a3-2631-4ad7-f53c-27965146b5a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: First Citizen\n",
            "Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx2char[ints])\n",
        "\n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdP53MAMlVCA",
        "outputId": "222a5703-4336-4ac6-e275-1c714f5604a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Examples"
      ],
      "metadata": {
        "id": "XMnNuixRnzX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "metadata": {
        "id": "nexeMSQHl7UW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "cMtcWqtUoM1M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "PrqV7IDEocdR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dataset.take(2):\n",
        "  print(\"\\n\\nEXAMPLE\\n\")\n",
        "  print(\"INPUT\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"\\nOUTPUT\")\n",
        "  print(int_to_text(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A1a6-Fpposr",
        "outputId": "43a718e4-ca9f-4a70-d124-088e3aa7a10e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "\n",
            "OUTPUT\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "\n",
            "OUTPUT\n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Batches"
      ],
      "metadata": {
        "id": "cqPejjAtq4Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "pPzULMJpqGim"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "gZRrQp479819"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Option 1: Sequential API (simplest, stateless LSTM)\n",
        "#If you don’t need stateful=True, just use Sequential cleanly:\n",
        "\n",
        "# def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "#     model = tf.keras.Sequential([\n",
        "#         tf.keras.layers.Embedding(vocab_size, embedding_dim, input_shape=(None,)),\n",
        "#         tf.keras.layers.LSTM(rnn_units,\n",
        "#                              return_sequences=True,\n",
        "#                              recurrent_initializer='glorot_uniform'),\n",
        "#         tf.keras.layers.Dense(vocab_size)\n",
        "#     ])\n",
        "#     return model\n",
        "\n",
        "# model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "# Option 2: Functional API (needed if stateful=True)\n",
        "# If you must use a stateful LSTM, build with the functional API:\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    inputs = tf.keras.layers.Input(batch_shape=(batch_size, None))\n",
        "    x = tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "    x = tf.keras.layers.LSTM(rnn_units,\n",
        "                             return_sequences=True,\n",
        "                             stateful=True,\n",
        "                             recurrent_initializer='glorot_uniform')(x)\n",
        "    outputs = tf.keras.layers.Dense(vocab_size)(x)\n",
        "\n",
        "    return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "pz6sOAZfrXme",
        "outputId": "290903cc-086b-43f8-a35a-331d2e760f58"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m16,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │     \u001b[38;5;34m5,246,976\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)         │        \u001b[38;5;34m66,625\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,976</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,625</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,330,241\u001b[0m (20.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,330,241</span> (20.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,330,241\u001b[0m (20.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,330,241</span> (20.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbQqY9ypD0lN",
        "outputId": "20e81a5c-080c-4644-fcff-f27f11bf741b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Nd9Ue6xfLOPv",
        "outputId": "669c2878-416e-4c45-e4f2-8c0b6c60981d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[ 0.00786513  0.0062862  -0.00371203 ... -0.00442869  0.00371211\n",
            "   -0.00366103]\n",
            "  [ 0.00491013  0.00668259 -0.00766491 ... -0.00464759  0.00495248\n",
            "   -0.00640829]\n",
            "  [ 0.00296024  0.00688455 -0.01072411 ... -0.00522768  0.00562367\n",
            "   -0.0088132 ]\n",
            "  ...\n",
            "  [ 0.00041989 -0.00219758 -0.01073858 ...  0.00415038  0.0083595\n",
            "   -0.01596026]\n",
            "  [ 0.00304538 -0.00376219 -0.01279312 ...  0.00561359  0.00517232\n",
            "   -0.00985358]\n",
            "  [ 0.01030111  0.00290691 -0.01395492 ...  0.00083042  0.00638521\n",
            "   -0.01184054]]\n",
            "\n",
            " [[ 0.00699978  0.00165385  0.00037607 ...  0.00061798 -0.00382203\n",
            "   -0.00363508]\n",
            "  [-0.00206175  0.00193184 -0.005914   ...  0.00069749  0.00066895\n",
            "   -0.00078589]\n",
            "  [ 0.00241973  0.0003699   0.00279437 ...  0.0004007   0.00529348\n",
            "    0.00137515]\n",
            "  ...\n",
            "  [ 0.0033033  -0.01111963 -0.00911675 ...  0.00898646  0.0020718\n",
            "   -0.01173422]\n",
            "  [-0.00272089 -0.00770405 -0.00673998 ...  0.00071324  0.00324975\n",
            "   -0.00846773]\n",
            "  [ 0.00262563 -0.00383085 -0.00681848 ... -0.00326883  0.00393234\n",
            "   -0.00868817]]\n",
            "\n",
            " [[-0.00076341 -0.00078978  0.00010593 ...  0.00531406  0.00061974\n",
            "    0.00207621]\n",
            "  [-0.000821   -0.00151509 -0.00310884 ...  0.00620324  0.0021812\n",
            "    0.00300138]\n",
            "  [-0.00019378 -0.00278342 -0.0078512  ...  0.00753772  0.00507605\n",
            "   -0.00532211]\n",
            "  ...\n",
            "  [ 0.00445897 -0.00124391 -0.00817421 ...  0.00977187 -0.00157453\n",
            "   -0.00361117]\n",
            "  [ 0.01238898 -0.0028572  -0.00942642 ...  0.00615674  0.00311733\n",
            "   -0.00380935]\n",
            "  [ 0.01033332 -0.00730592 -0.00844865 ...  0.00410162 -0.0023405\n",
            "   -0.00245256]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.00247959  0.0053761   0.00438182 ...  0.00190255  0.0027571\n",
            "   -0.00267882]\n",
            "  [ 0.00948798  0.00607472  0.00318345 ...  0.00276886 -0.00165188\n",
            "   -0.00649911]\n",
            "  [ 0.0078538   0.00553481 -0.00323387 ...  0.00625437  0.00219666\n",
            "   -0.01353411]\n",
            "  ...\n",
            "  [ 0.00045431 -0.00064292 -0.00511353 ... -0.00033767  0.0060469\n",
            "   -0.00402342]\n",
            "  [-0.00431259 -0.00161012 -0.00067111 ...  0.00075346  0.00680622\n",
            "   -0.00402781]\n",
            "  [-0.00272074 -0.00190084 -0.00440879 ...  0.00407079  0.00937155\n",
            "   -0.01104757]]\n",
            "\n",
            " [[-0.00170755  0.00941033 -0.00044688 ... -0.00019962  0.00421052\n",
            "    0.0055375 ]\n",
            "  [ 0.004113    0.00013928 -0.00361408 ...  0.00296312  0.00365504\n",
            "    0.00059716]\n",
            "  [-0.00210038  0.00233175 -0.00237134 ... -0.00408112  0.00432907\n",
            "    0.00110622]\n",
            "  ...\n",
            "  [ 0.00776762 -0.00655696 -0.00689344 ...  0.00424527  0.00427444\n",
            "   -0.011955  ]\n",
            "  [ 0.00693351 -0.01000842 -0.0051345  ...  0.00039273 -0.00165203\n",
            "   -0.01072848]\n",
            "  [ 0.01025913 -0.00763479 -0.00227836 ... -0.00633337 -0.00630003\n",
            "   -0.0082659 ]]\n",
            "\n",
            " [[-0.00089395  0.00244486 -0.00566653 ... -0.00177206  0.00205151\n",
            "   -0.0028019 ]\n",
            "  [-0.00022271  0.00125117 -0.00794877 ...  0.00127752  0.00322813\n",
            "   -0.00062169]\n",
            "  [-0.00700734 -0.00045502 -0.01285958 ...  0.00063861  0.00621184\n",
            "    0.00186707]\n",
            "  ...\n",
            "  [ 0.00743168  0.00194592  0.00672434 ...  0.00314552  0.00774131\n",
            "   -0.01384139]\n",
            "  [ 0.0051411   0.00174163  0.00065457 ...  0.00808923  0.00968726\n",
            "   -0.01912981]\n",
            "  [ 0.00785477 -0.00608124 -0.00235305 ...  0.01040457  0.00764487\n",
            "   -0.01764269]]], shape=(64, 100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5umVLmaL0g2",
        "outputId": "8009562d-51e5-4461-d745-79243b7749be"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[ 0.00786513  0.0062862  -0.00371203 ... -0.00442869  0.00371211\n",
            "  -0.00366103]\n",
            " [ 0.00491013  0.00668259 -0.00766491 ... -0.00464759  0.00495248\n",
            "  -0.00640829]\n",
            " [ 0.00296024  0.00688455 -0.01072411 ... -0.00522768  0.00562367\n",
            "  -0.0088132 ]\n",
            " ...\n",
            " [ 0.00041989 -0.00219758 -0.01073858 ...  0.00415038  0.0083595\n",
            "  -0.01596026]\n",
            " [ 0.00304538 -0.00376219 -0.01279312 ...  0.00561359  0.00517232\n",
            "  -0.00985358]\n",
            " [ 0.01030111  0.00290691 -0.01395492 ...  0.00083042  0.00638521\n",
            "  -0.01184054]], shape=(100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_pred = pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FggE5IqhMmZN",
        "outputId": "3874deda-0343-456a-d7b9-afb06a676969"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[ 0.00786513  0.0062862  -0.00371203  0.00426101 -0.00266908  0.00386203\n",
            " -0.00190128 -0.00107597 -0.00167902 -0.00160444 -0.00054469 -0.00418652\n",
            " -0.00261001  0.00055958 -0.00228554 -0.00132797 -0.00255626  0.00342881\n",
            " -0.00225848  0.00381575  0.00068623 -0.00242871 -0.00099379 -0.00092308\n",
            "  0.00526732  0.0011703  -0.00054854 -0.00263492  0.00047431  0.00332117\n",
            "  0.00458129  0.00202945 -0.00519435  0.00124015 -0.00315216 -0.004338\n",
            " -0.00326751 -0.0039294  -0.00366595  0.00077512 -0.00354914 -0.00784563\n",
            " -0.00465124  0.00364712 -0.0024905   0.00297591  0.00315593 -0.00080676\n",
            "  0.00607526  0.00935796 -0.00215229  0.00264851 -0.00023754  0.00159578\n",
            "  0.00281221  0.00037538 -0.00506521 -0.00629953  0.00035914  0.00095056\n",
            " -0.00077588  0.00402978 -0.00442869  0.00371211 -0.00366103], shape=(65,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices =  tf.random.categorical(pred, num_samples=1)\n",
        "\n",
        "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
        "predicted_chars = int_to_text(sampled_indices)\n",
        "\n",
        "predicted_chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5S2pLN0RNJZF",
        "outputId": "74638787-5f5c-4b4d-85fd-c299b7ee9c3d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'EoA:&nDSRwrgs:TYP&UQmNMkPQr;EXlfEZtjmJM!eB&H&DZu ?WfBLeAnemr Z&mHirlN!BIlJlp-PeuEqxg3WHEcmV.3fU&\\n,lF'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "metadata": {
        "id": "_db2naToNzPm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile and Checkpoints"
      ],
      "metadata": {
        "id": "0iPbljCtwhp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "rfzq5qFHwgqg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix =  os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "UWkjpWxXwwCo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Loading the Model"
      ],
      "metadata": {
        "id": "HmKQfIbfySJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46Eqq4PPxrtC",
        "outputId": "9ad1bf56-c165-42fd-8884-55144c4f9d90"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 68ms/step - loss: 2.6838\n",
            "Epoch 2/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 69ms/step - loss: 1.8099\n",
            "Epoch 3/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 71ms/step - loss: 1.5665\n",
            "Epoch 4/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 1.4492\n",
            "Epoch 5/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - loss: 1.3845\n",
            "Epoch 6/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 75ms/step - loss: 1.3311\n",
            "Epoch 7/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 1.2934\n",
            "Epoch 8/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 1.2565\n",
            "Epoch 9/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - loss: 1.2232\n",
            "Epoch 10/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 1.1895\n",
            "Epoch 11/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 77ms/step - loss: 1.1565\n",
            "Epoch 12/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - loss: 1.1213\n",
            "Epoch 13/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 1.0879\n",
            "Epoch 14/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 1.0524\n",
            "Epoch 15/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 76ms/step - loss: 1.0152\n",
            "Epoch 16/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.9780\n",
            "Epoch 17/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - loss: 0.9419\n",
            "Epoch 18/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - loss: 0.9056\n",
            "Epoch 19/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 77ms/step - loss: 0.8690\n",
            "Epoch 20/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.8320\n",
            "Epoch 21/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.7987\n",
            "Epoch 22/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.7665\n",
            "Epoch 23/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - loss: 0.7341\n",
            "Epoch 24/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 77ms/step - loss: 0.7075\n",
            "Epoch 25/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 78ms/step - loss: 0.6800\n",
            "Epoch 26/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.6548\n",
            "Epoch 27/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.6335\n",
            "Epoch 28/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.6108\n",
            "Epoch 29/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.5902\n",
            "Epoch 30/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.5719\n",
            "Epoch 31/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.5568\n",
            "Epoch 32/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.5441\n",
            "Epoch 33/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 79ms/step - loss: 0.5286\n",
            "Epoch 34/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 80ms/step - loss: 0.5181\n",
            "Epoch 35/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.5061\n",
            "Epoch 36/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.4947\n",
            "Epoch 37/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.4871\n",
            "Epoch 38/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.4800\n",
            "Epoch 39/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 79ms/step - loss: 0.4702\n",
            "Epoch 40/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.4632\n",
            "Epoch 41/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.4566\n",
            "Epoch 42/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 77ms/step - loss: 0.4532\n",
            "Epoch 43/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.4471\n",
            "Epoch 44/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.4387\n",
            "Epoch 45/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.4366\n",
            "Epoch 46/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.4332\n",
            "Epoch 47/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - loss: 0.4271\n",
            "Epoch 48/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 78ms/step - loss: 0.4252\n",
            "Epoch 49/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.4237\n",
            "Epoch 50/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 76ms/step - loss: 0.4179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(checkpoint_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_isZfvdz5xhc",
        "outputId": "bb60dec7-2458-4b68-df2e-1c73d6cd5cbe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ckpt_35.weights.h5', 'ckpt_33.weights.h5', 'ckpt_1.weights.h5', 'ckpt_25.weights.h5', 'ckpt_20.weights.h5', 'ckpt_29.weights.h5', 'ckpt_6.weights.h5', 'ckpt_13.weights.h5', 'ckpt_41.weights.h5', 'ckpt_27.weights.h5', 'ckpt_46.weights.h5', 'ckpt_37.weights.h5', 'ckpt_49.weights.h5', 'ckpt_2.weights.h5', 'ckpt_32.weights.h5', 'ckpt_18.weights.h5', 'ckpt_21.weights.h5', 'ckpt_14.weights.h5', 'ckpt_10.weights.h5', 'ckpt_9.weights.h5', 'ckpt_15.weights.h5', 'ckpt_16.weights.h5', 'ckpt_44.weights.h5', 'ckpt_50.weights.h5', 'ckpt_30.weights.h5', 'ckpt_23.weights.h5', 'ckpt_42.weights.h5', 'ckpt_34.weights.h5', 'ckpt_17.weights.h5', 'ckpt_7.weights.h5', 'ckpt_31.weights.h5', 'ckpt_24.weights.h5', 'ckpt_8.weights.h5', 'ckpt_45.weights.h5', 'ckpt_38.weights.h5', 'ckpt_28.weights.h5', 'ckpt_11.weights.h5', 'ckpt_43.weights.h5', 'ckpt_40.weights.h5', 'ckpt_19.weights.h5', 'ckpt_39.weights.h5', 'ckpt_26.weights.h5', 'ckpt_12.weights.h5', 'ckpt_5.weights.h5', 'ckpt_36.weights.h5', 'ckpt_4.weights.h5', 'ckpt_48.weights.h5', 'ckpt_3.weights.h5', 'ckpt_22.weights.h5', 'ckpt_47.weights.h5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
      ],
      "metadata": {
        "id": "3BvYWzDa69k6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latest_checkpoint_path = os.path.join(checkpoint_dir, \"ckpt_50.weights.h5\")\n",
        "\n",
        "model.load_weights(latest_checkpoint_path)\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "gvDuVXtayW5K"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To check if checkpoint exists\n",
        "# import os\n",
        "\n",
        "# checkpoint_path = os.path.join(checkpoint_dir, \"ckpt_2.weights.h5\")\n",
        "\n",
        "# if os.path.exists(checkpoint_path):\n",
        "#     model.load_weights(checkpoint_path)\n",
        "#     model.build(tf.TensorShape([1, None]))\n",
        "#     print(f\"✅ Loaded weights from {checkpoint_path}\")\n",
        "# else:\n",
        "#     print(\"⚠️ Checkpoint for epoch 10 not found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9BR_frx71GH",
        "outputId": "71fa835c-d07f-4795-a7ac-74d7c2b0aa6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded weights from ./training_checkpoints/ckpt_2.weights.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(checkpoint_dir, \"ckpt_33.weights.h5\")\n",
        "\n",
        "model.load_weights(checkpoint_path)\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "print(f\"✅ Loaded weights from {checkpoint_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAA2HoTJy2Wz",
        "outputId": "953fe30d-1d3e-47dd-a45d-133e11e0c348"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded weights from ./training_checkpoints/ckpt_33.weights.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating Text"
      ],
      "metadata": {
        "id": "kimdSrNA1ToV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from inspect import ismemberdescriptor\n",
        "def generate_text(model, start_string):\n",
        "  num_generate = 800\n",
        "\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated = []\n",
        "  temperature =  1.0\n",
        "\n",
        "  # model.reset_states() # This is not the correct way to reset states for a functional model,\n",
        "  #only for ststeful=True RNN model\n",
        "  for i in range(num_generate):\n",
        "\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "    predictions = predictions/temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "1xxV42pR1Vu_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = input(\"Type a string starting: \")\n",
        "print(generate_text(model, inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCihrtll8LsX",
        "outputId": "71db31ac-b9ce-4835-b28d-625dedb5f84b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type a string starting: Romeo\n",
            "Romeo.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "Read no more, I did: it is a man\n",
            "To chamber where he shall attend and s\n",
            "e tongues? O myself,\n",
            "Itake on our channel service\n",
            "Being warm'd with the coffence? Speak not for strong,\n",
            "And all the promisues of his son took somewhat is happines;\n",
            "De\n",
            "Contain as the last, I emp supdosed hath tune his hands.\n",
            "\n",
            "WARWICK:\n",
            "Then I degrans thee, I, brow thee a person. say, where I am like too late!\n",
            "\n",
            "GLOUCESTER:\n",
            "Sweet pray,\n",
            "Her dukedom to of gring me\n",
            "But one of nevereig to the people mock'd.\n",
            "\n",
            "SICINIUS:\n",
            "Knoce I am an hundred breth\n",
            "To give him anon.\n",
            "\n",
            "ANGELO:\n",
            "Go wain, old Gaunt, take you you.\n",
            "\n",
            "LARTIUS:\n",
            "Hark, Perditan me a weardran. What\n",
            "was e here will I appear,\n",
            "Accompany more four ancount of worship, breasts, invisube vouch,\n",
            "To die for your title to them;\n",
            "And more, more love.\n",
            "\n",
            "GEONA:\n",
            "Why, Camil\n"
          ]
        }
      ]
    }
  ]
}